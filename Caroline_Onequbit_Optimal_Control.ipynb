{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Caroline_Onequbit_Optimal_Control.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO6g2FYCFkD87hLPiRwxe6x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarolineLaure/One_Qubit_TensorFlow_example/blob/master/Caroline_Onequbit_Optimal_Control.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj9h-cu3sdaj",
        "colab_type": "code",
        "outputId": "c7537488-0627-4813-f466-f784c313c593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from keras import backend as K\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "print(tf.__version__)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABw__RQNsiUT",
        "colab_type": "code",
        "outputId": "31169c7a-cfd8-43b3-965d-ef077e4d3464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "#Deleseleuc parameters\n",
        "\n",
        "delta1 = tf.Variable(2*np.pi*560*10**6, dtype=tf.complex128)\n",
        "sigma_total = tf.Variable(2*np.pi*13*10**3, dtype=tf.complex128)\n",
        "delta2 = tf.Variable(-delta1+sigma_total, dtype=tf.complex128)\n",
        "Omega1 = tf.Variable(2*np.pi*60*10**6, dtype=tf.complex128)\n",
        "Omega2 = tf.Variable(2*np.pi*36*10**6, dtype=tf.complex128)\n",
        "delta_t = tf.Variable(10**(-7), dtype=tf.complex128)\n",
        "\n",
        "class Propagator:\n",
        "    def __init__(self, no_of_steps, delta_t, delta1, delta2, sigma_total, Omega1, Omega2, dim):\n",
        "        \n",
        "        self.dim=3\n",
        "        self.delta_t = delta_t\n",
        "        self.x1 = tf.constant(\n",
        "            [[0, 1, 0], [1, 0, 0], [0, 0, 0]], dtype=tf.complex128\n",
        "        )\n",
        "        self.x2 = tf.constant(\n",
        "            [[0 , 0, 0], [0, 0, 1], [1, 0, 0]], dtype=tf.complex128\n",
        "        )\n",
        "\n",
        "        self.x3 = tf.constant(\n",
        "            [[0 , 0, 0], [0, 1, 0], [0, 0, 1]], dtype=tf.complex128\n",
        "        )\n",
        "\n",
        "        self.x4 = tf.constant(\n",
        "            [[0 , 0, 0], [0, 0, 0], [0, 0, 1]], dtype=tf.complex128\n",
        "        )\n",
        "\n",
        "        self.generators = tf.stack([self.x3, self.x4, self.x1, self.x2])   \n",
        "        self.ctrl_amplitudes = tf.Variable(\n",
        "            tf.zeros([no_of_steps, 4], dtype=tf.float64), dtype=tf.float64\n",
        "        )\n",
        "\n",
        "        \"\"\"\n",
        "            self.contraction_array determines the neccessity for the extra\n",
        "            matrix multiplication step in the recursive method self.propagate()\n",
        "            when the intermediate computation array has length not divisible\n",
        "            by 2\n",
        "        \"\"\"\n",
        "        self.contraction_array = []\n",
        "        contraction_array_length = int(np.floor(np.log2(no_of_steps)))\n",
        "        temp_no_of_steps = no_of_steps\n",
        "        for i in range(contraction_array_length):\n",
        "            self.contraction_array.append(bool(np.mod(temp_no_of_steps, 2)))\n",
        "            temp_no_of_steps = np.floor(temp_no_of_steps / 2)\n",
        "  \n",
        "    \"\"\"\n",
        "        exponentials() computes a vector matrix exponential after multiplying\n",
        "        each self.ctrl_amplitudes row with a the vector of matrices in\n",
        "        self.generators\n",
        "    \"\"\"\n",
        "    def exponentials(self):\n",
        "        regularized_amplitudes = 1 / np.sqrt(2) * tf.math.tanh(\n",
        "            self.ctrl_amplitudes\n",
        "        )\n",
        "\n",
        "        @keras_export('keras.backend.repeat')\n",
        "        K.constant_part = K.(- delta1 * self.x3 - sigma_total * self.x4)\n",
        "\n",
        "        exponents = -2 * np.pi *(0 + 1j) * self.delta_t * tf.linalg.tensordot(\n",
        "            tf.cast(regularized_amplitudes, dtype=tf.complex128),\n",
        "            (- (Omega1/2) * self.x1 - (Omega2/2) * self.x2), 1\n",
        "        )\n",
        "        return tf.linalg.expm(constant_part + exponents)\n",
        "    \n",
        "    \"\"\"\n",
        "        propagate  computes the final propagator by recursively multiplying\n",
        "        each odd element in the list of matrices with each even element --\n",
        "        if the length of the array is not divisible by 2 an extra computation\n",
        "        step is added\n",
        "    \"\"\"\n",
        "    def propagate(self):\n",
        "        step_exps = self.exponentials()\n",
        "        for is_odd in self.contraction_array:\n",
        "            if is_odd:\n",
        "                odd_exp = step_exps[-1, :, :]\n",
        "                step_exps = tf.linalg.matmul(\n",
        "                    step_exps[1::2, :, :], step_exps[0:-1:2, :, :]\n",
        "                )\n",
        "                step_exps = tf.concat([\n",
        "                    step_exps[0:-1, :, :],\n",
        "                    [tf.linalg.matmul(odd_exp, step_exps[-1, :, :])]\n",
        "                ], 0)\n",
        "            else:\n",
        "                step_exps = tf.linalg.matmul(\n",
        "                    step_exps[1::2, :, :], step_exps[0::2, :, :]\n",
        "                )\n",
        "        return tf.squeeze(step_exps)\n",
        "\n",
        "    \"\"\"\n",
        "        __call__ computes the final propagator fidelity squared with the\n",
        "        identity operator\n",
        "    \"\"\"\n",
        "    \n",
        "    @tf.function\n",
        "    def infidelity(self):\n",
        "        propagator = self.propagate()\n",
        "        x1 = tf.cast(\n",
        "            [1, 0, 0], dtype=tf.complex128 \n",
        "        )                                                                   # My ground state\n",
        "        x2 = tf.cast(\n",
        "            [0 , 0, 1], dtype=tf.complex128                                 # My excited state\n",
        "        )\n",
        "        final_state = tf.linalg.matvec(propagator, tf.transpose(x1))\n",
        "        Overlap = tf.tensordot(tf.math.conj(final_state), x2 )\n",
        "        return 1 - tf.math.real((tf.math.conj(overlap) * overlap))\n",
        "\n",
        "#propagator = Propagator(1000, 10**(-7), 3)\n",
        "\n",
        "propagator = Propagator(1000, delta_t, delta1, delta2, sigma_total, Omega1, Omega2, 4)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(0.01)\n",
        "\n",
        "propagator.ctrl_amplitudes.assign(\n",
        "    tf.random.uniform([1000, 4], -1, 1, dtype=tf.float64)\n",
        ")\n",
        "\n",
        "propagator.propagate()\n",
        "\n",
        "\n",
        "def optimization_step():\n",
        "    with tf.GradientTape() as tape:\n",
        "        infidelity = propagator.infidelity()\n",
        "    gradients = tape.gradient(infidelity, [propagator.ctrl_amplitudes])\n",
        "    optimizer.apply_gradients(zip(gradients, [propagator.ctrl_amplitudes]))\n",
        "    return infidelity\n",
        "\n",
        "steps = range(100)\n",
        "for step in steps:\n",
        "    current_infidelity = optimization_step()\n",
        "    print('step %2d: infidelity=%2.5f' %\n",
        "          (step, current_infidelity))    \n",
        "propagator.ctrl_amplitudes.numpy()\n",
        "\n",
        "#propagator.delta_t\n",
        "#propagator.no_of_steps"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-06c7031462fc>\"\u001b[0;36m, line \u001b[0;32m58\u001b[0m\n\u001b[0;31m    K.constant_part = K.(- delta1 * self.x3 - sigma_total * self.x4)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpP51msMBEwj",
        "colab_type": "text"
      },
      "source": [
        "My Hamiltonian is: -\\delta|e><e| - sigma_total |r><r| - (Omega1/2)(|g><e| + |e><g|) - (Omega2/2)(|e><r| + |r><e|)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXfUDjWJKfTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}